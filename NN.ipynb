{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a60c5b",
   "metadata": {},
   "source": [
    "# Index   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834dfc1",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a57c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import  applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Conv1D, MaxPool2D,GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix ,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6988ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "import os\n",
    "import pathlib\n",
    "#import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b223310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow_hub as hub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"KMP_WARNINGS\"] = \"FALSE\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5930eeb2",
   "metadata": {},
   "source": [
    "# Building the neuronal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/@himancodes/building-an-image-classifier-from-scratch-using-convolutional-neural-networks-c9ebcde3a53e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e9cb9",
   "metadata": {},
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "base = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "tf.keras.backend.clear_session()\n",
    "    \n",
    "for layer in base.layers:\n",
    "    layer.trainable =  False\n",
    "\n",
    "mobilenet_model = Sequential()\n",
    "mobilenet_model.add(base)\n",
    "mobilenet_model.add(GlobalAveragePooling2D())\n",
    "\n",
    "mobilenet_model.add(Dense(256, activation='relu'))\n",
    "mobilenet_model.add(Dropout(0.1))\n",
    "\n",
    "mobilenet_model.add(Dense(256, activation='relu'))\n",
    "mobilenet_model.add(Dropout(0.1))\n",
    "mobilenet_model.add(Dense(3, activation='softmax')) #last layer should have as many neuron as options = 3 sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f29da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder structure\n",
    "\n",
    "|--image-classification (folder)\n",
    "|--|--dataset (folder)\n",
    "|--|--|--train (folder)\n",
    "|--|--|--|--cowbell (folder)\n",
    "|--|--|--|--|--image_1.jpg\n",
    "|--|--|--|--|--image_2.jpg\n",
    "|--|--|--|--|--...\n",
    "|--|--|--|--tulip (folder)\n",
    "|--|--|--|--|--image_1.jpg\n",
    "|--|--|--|--|--image_2.jpg\n",
    "|--|--|--|--|--...\n",
    "|--|--|--test (folder)\n",
    "|--|--|--|--image_1.jpg\n",
    "|--|--|--|--image_2.jpg\n",
    "|--|--output (folder)\n",
    "|--|--|--data.h5\n",
    "|--|--|--labels.h5\n",
    "|--|--global.py\n",
    "|--|--train_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43196f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ae89ae0",
   "metadata": {},
   "source": [
    "To implement f1 macro score in Keras should be done in one of the following solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "# https://www.kaggle.com/code/guglielmocamporese/macro-f1-score-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "    def  on_train_begin(self,logs={}):\n",
    "      self.f1_macro=[]\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "      y_pred=self.model.predict(x_test).round()\n",
    "      y_true=y_test\n",
    "      score=f1_score(y_true, y_pred, average='macro')\n",
    "      self.f1_macro.append(score)\n",
    "      print(\" F1 macro :\",score)\n",
    "\n",
    "metrics=MetricsCallback()\n",
    "\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test),batch_size=batch_size, epochs=5,callbacks=[metrics])\n",
    "\n",
    "# https://colab.research.google.com/drive/1hTf0LjO-h2l6diVkvj0gQme25clUdFt2#scrollTo=S3hxXkGocmUq\n",
    "# https://androidkt.com/calculate-f1-macro-in-keras/\n",
    "\n",
    "# multiclass f1 macro score https://towardsdatascience.com/f-beta-score-in-keras-part-ii-15f91f07c9a4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9931293",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f49608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e681a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASK(keras.callbacks.Callback):\n",
    "    def __init__ (self, model, epochs,  ask_epoch): # initialization of the callback\n",
    "        super(ASK, self).__init__()\n",
    "        self.model=model               \n",
    "        self.ask_epoch=ask_epoch\n",
    "        self.epochs=epochs\n",
    "        self.ask=True # if True query the user on a specified epoch\n",
    "        \n",
    "    def on_train_begin(self, logs=None): # this runs on the beginning of training\n",
    "        if self.ask_epoch == 0: \n",
    "            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n",
    "            self.ask_epoch=1\n",
    "        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n",
    "            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n",
    "            self.ask=False # do not query the user\n",
    "        if self.epochs == 1:\n",
    "            self.ask=False # running only for 1 epoch so do not query user\n",
    "        else:\n",
    "            print('Training will proceed until epoch', ask_epoch,' then you will be asked to') \n",
    "            print(' enter H to halt training or enter an integer for how many more epochs to run then be asked again')  \n",
    "        self.start_time= time.time() # set the time at which training started\n",
    "        \n",
    "    def on_train_end(self, logs=None):   # runs at the end of training     \n",
    "        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n",
    "        hours = tr_duration // 3600\n",
    "        minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
    "        print (msg, flush=True) # print out training duration time\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        if self.ask: # are the conditions right to query the user?\n",
    "            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n",
    "                print('\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again')\n",
    "                ans=input()\n",
    "                \n",
    "                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n",
    "                    print ('you entered ', ans, ' Training halted on epoch ', epoch+1, ' due to user input\\n', flush=True)\n",
    "                    self.model.stop_training = True # halt training\n",
    "                else: # user wants to continue training\n",
    "                    self.ask_epoch += int(ans)\n",
    "                    if self.ask_epoch > self.epochs:\n",
    "                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n",
    "                    else:\n",
    "                        print ('you entered ', ans, ' Training will continue to epoch ', self.ask_epoch, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e3e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate custom callback and create 2 callbacks to control learning rate and early stop\n",
    "\n",
    "epochs=40\n",
    "ask_epoch=10\n",
    "ask=ASK(model, epochs,  ask_epoch)\n",
    "rlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\n",
    "estop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, verbose=1,restore_best_weights=True)\n",
    "callbacks=[rlronp, estop, ask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03613a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "'''Note unlike how you are told it is BETTER to make the base model trainable from the outset\n",
    "It will converge faster and have a lower validation losss'''\n",
    "\n",
    "history=model.fit(x=train_gen, \n",
    "                     epochs=epochs, \n",
    "                     verbose=1, \n",
    "                     callbacks=callbacks,  \n",
    "                     validation_data=valid_gen,\n",
    "                    validation_steps=None,  \n",
    "                    shuffle=False,  \n",
    "                    initial_epoch=0\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_plot(tr_data, start_epoch):\n",
    "    \n",
    "\n",
    "    \n",
    "    #Plot the training and validation data\n",
    "    tacc=tr_data.history['accuracy']\n",
    "    tloss=tr_data.history['loss']\n",
    "    vacc=tr_data.history['val_accuracy']\n",
    "    vloss=tr_data.history['val_loss']\n",
    "    Epoch_count=len(tacc)+ start_epoch\n",
    "    Epochs=[]\n",
    "    for i in range (start_epoch ,Epoch_count):\n",
    "        Epochs.append(i+1)   \n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    acc_highest=vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
    "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(test_gen, test_steps):\n",
    "    '''Define a function which takes in a test generator and an integer test_steps\n",
    "    and generates predictions on the test set including a confusion matrix\n",
    "    and a classification report'''\n",
    "    \n",
    "    y_pred= []\n",
    "    y_true=test_gen.labels\n",
    "    classes=list(train_gen.class_indices.keys())\n",
    "    class_count=len(classes)\n",
    "    errors=0\n",
    "    preds=model.predict(test_gen, steps=test_steps, verbose=1) # predict on the test set\n",
    "    tests=len(preds)\n",
    "    for i, p in enumerate(preds):\n",
    "            pred_index=np.argmax(p)         \n",
    "            true_index=test_gen.labels[i]  # labels are integer values\n",
    "            if pred_index != true_index: # a misclassification has occurred                                           \n",
    "                errors=errors + 1\n",
    "            y_pred.append(pred_index)\n",
    "    acc=( 1-errors/tests) * 100\n",
    "    print(f'there were {errors} in {tests} tests for an accuracy of {acc:6.2f}')\n",
    "    ypred=np.array(y_pred)\n",
    "    ytrue=np.array(y_true)\n",
    "    if class_count <=30:\n",
    "        cm = confusion_matrix(ytrue, ypred )\n",
    "        # plot the confusion matrix\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n",
    "        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create classification report\n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "  \n",
    "subject='bengali digits' \n",
    "acc=str(( 1-errors/tests) * 100)\n",
    "index=acc.rfind('.')\n",
    "acc=acc[:index + 3]\n",
    "save_id= subject + '_' + str(acc) + '.h5' \n",
    "model_save_loc=os.path.join(working_dir, save_id)\n",
    "model.save(model_save_loc)\n",
    "print ('model was saved as ' , model_save_loc ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2a Manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "train_path = '../input/sports-classification/train'\n",
    "valid_path = '../input/sports-classification/valid'\n",
    "test_path = '../input/sports-classification/test'\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import  applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Conv1D, MaxPool2D,GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix ,classification_report\n",
    "# import numpy as np \n",
    "# import pandas as pd \n",
    "import os\n",
    "import pathlib\n",
    "#import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow_hub as hub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"KMP_WARNINGS\"] = \"FALSE\" \n",
    "from tensorflow.keras import layers\n",
    "Transfer Learning\n",
    "train_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=train_path,target_size= (224,224),batch_size=10,shuffle=False)\n",
    "Found 13572 images belonging to 100 classes.\n",
    "test_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=test_path,target_size= (224,224),batch_size=10,shuffle=False)\n",
    "Found 500 images belonging to 100 classes.\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "base = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "tf.keras.backend.clear_session()\n",
    "    \n",
    "for layer in base.layers:\n",
    "    layer.trainable =  False\n",
    "\n",
    "mobilenet_model = Sequential()\n",
    "mobilenet_model.add(base)\n",
    "mobilenet_model.add(GlobalAveragePooling2D())\n",
    "\n",
    "mobilenet_model.add(Dense(256, activation='relu'))\n",
    "mobilenet_model.add(Dropout(0.1))\n",
    "\n",
    "mobilenet_model.add(Dense(256, activation='relu'))\n",
    "mobilenet_model.add(Dropout(0.1))\n",
    "mobilenet_model.add(Dense(100, activation='softmax'))\n",
    "2022-02-16 09:07:50.363094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:50.476936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:50.477632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:50.478711: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2022-02-16 09:07:50.479574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:50.480230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:50.480874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:52.268808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:52.269632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:52.270260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-02-16 09:07:52.270857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
    "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
    "9412608/9406464 [==============================] - 0s 0us/step\n",
    "9420800/9406464 [==============================] - 0s 0us/step\n",
    "mobilenet_model.summary()\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
    "_________________________________________________________________\n",
    "global_average_pooling2d (Gl (None, 1280)              0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 256)               327936    \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 256)               65792     \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 100)               25700     \n",
    "=================================================================\n",
    "Total params: 2,677,412\n",
    "Trainable params: 419,428\n",
    "Non-trainable params: 2,257,984\n",
    "_________________________________________________________________\n",
    "mobilenet_model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "results=mobilenet_model.fit(train_batches,epochs=10)  \n",
    "2022-02-16 09:07:54.446711: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
    "Epoch 1/10\n",
    "2022-02-16 09:07:57.726453: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
    "1358/1358 [==============================] - 100s 67ms/step - loss: 3.8587 - accuracy: 0.1648\n",
    "Epoch 2/10\n",
    "1358/1358 [==============================] - 39s 28ms/step - loss: 1.8174 - accuracy: 0.5371\n",
    "Epoch 3/10\n",
    "1358/1358 [==============================] - 38s 28ms/step - loss: 1.1337 - accuracy: 0.6905\n",
    "Epoch 4/10\n",
    "1358/1358 [==============================] - 39s 28ms/step - loss: 0.8724 - accuracy: 0.7543\n",
    "Epoch 5/10\n",
    "1358/1358 [==============================] - 39s 29ms/step - loss: 0.6977 - accuracy: 0.7996\n",
    "Epoch 6/10\n",
    "1358/1358 [==============================] - 38s 28ms/step - loss: 0.5712 - accuracy: 0.8296\n",
    "Epoch 7/10\n",
    "1358/1358 [==============================] - 39s 28ms/step - loss: 0.4902 - accuracy: 0.8528\n",
    "Epoch 8/10\n",
    "1358/1358 [==============================] - 39s 29ms/step - loss: 0.4212 - accuracy: 0.8748\n",
    "Epoch 9/10\n",
    "1358/1358 [==============================] - 39s 28ms/step - loss: 0.3493 - accuracy: 0.8974\n",
    "Epoch 10/10\n",
    "1358/1358 [==============================] - 39s 29ms/step - loss: 0.3070 - accuracy: 0.9119\n",
    "mobilenet_model.evaluate(test_batches)\n",
    "50/50 [==============================] - 4s 69ms/step - loss: 0.2401 - accuracy: 0.9220\n",
    "[0.24005533754825592, 0.921999990940094]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.summary()\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
    "_________________________________________________________________\n",
    "global_average_pooling2d (Gl (None, 1280)              0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 256)               327936    \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 256)               65792     \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 100)               25700     \n",
    "=================================================================\n",
    "Total params: 2,677,412\n",
    "Trainable params: 419,428\n",
    "Non-trainable params: 2,257,984\n",
    "_________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c93407",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "results=mobilenet_model.fit(train_batches,epochs=10)  \n",
    "\n",
    "\n",
    "2022-02-16 09:07:54.446711: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
    "Epoch 1/10\n",
    "2022-02-16 09:07:57.726453: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
    "1358/1358 [==============================] - 100s 67ms/step - loss: 3.8587 - accuracy: 0.1648\n",
    "Epoch 2/10\n",
    "1358/1358 [==============================] - 39s 28ms/step - loss: 1.8174 - accuracy: 0.5371\n",
    "Epoch 3/10\n",
    "1358/1358 [==============================] - 38s 28ms/step - loss: 1.1337 - accuracy: 0.6905\n",
    "Epoch 4/10\n",
    "1358/1358 [==============================] - 39s 28ms/step - loss: 0.8724 - accuracy: 0.7543\n",
    "Epoch 5/10\n",
    "1358/1358 [==============================] - 39s 29ms/step - loss: 0.6977 - accuracy: 0.7996\n",
    "Epoch 6/10\n",
    "1358/1358 [==============================] - 38s 28ms/step - loss: 0.5712 - accuracy: 0.8296\n",
    "Epoch 7/10\n",
    "1358/1358 [==============================] - 39s 28ms/step - loss: 0.4902 - accuracy: 0.8528\n",
    "Epoch 8/10\n",
    "1358/1358 [==============================] - 39s 29ms/step - loss: 0.4212 - accuracy: 0.8748\n",
    "Epoch 9/10\n",
    "1358/1358 [==============================] - 39s 28ms/step - loss: 0.3493 - accuracy: 0.8974\n",
    "Epoch 10/10\n",
    "1358/1358 [==============================] - 39s 29ms/step - loss: 0.3070 - accuracy: 0.9119\n",
    "mobilenet_model.evaluate(test_batches)\n",
    "50/50 [==============================] - 4s 69ms/step - loss: 0.2401 - accuracy: 0.9220\n",
    "[0.24005533754825592, 0.921999990940094]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728cf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea340a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d428f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NeuronalNetwork')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ba370917a355ec78ddf17e7842e8975915af0e08f57c7dd5296cba069c129853"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
